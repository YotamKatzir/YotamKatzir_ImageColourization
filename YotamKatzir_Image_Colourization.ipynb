{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YotamKatzir/YotamKatzir_ImageColourization/blob/main/YotamKatzir_Image_Colourization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Isl7sTxNxY21"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageOps\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuv1PPl_qo6p"
      },
      "source": [
        "לאימון נשתמש במעבד מסוג יע\"ט (TPU - Tensor processing unit)\n",
        "\n",
        "נגדירו:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "wUnwoxP0sOc6",
        "outputId": "a26aa697-6e0f-497c-f1f2-c91485fc1f5d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-01e70b14496e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# קוד איתחול היע\"ט שצריך להגדיר בתחילת הפרויקט כדי שזה יוכל לעבוד.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All devices: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    201\u001b[0m           \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m           \u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m           discovery_url=discovery_url)\n\u001b[0m\u001b[1;32m    204\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cloud_tpu_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/tpu/client/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please provide a TPU Name to connect to.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please provide a TPU Name to connect to."
          ]
        }
      ],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# קוד איתחול היע\"ט שצריך להגדיר בתחילת הפרויקט כדי שזה יוכל לעבוד.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHPXpCUrKtl2"
      },
      "source": [
        "# חלק 1: הכנת הנתונים\n",
        "בחלק זה אעבור על התמונות הצבעוניות ואעבד אותן לכדי תמונות בגווני אפור."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5deGOBbM-_6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/MyDrive/Deep_Learning/PortraitData.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m-mdWp1LE7N"
      },
      "outputs": [],
      "source": [
        "# גודל האצווה לאימון\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 60000\n",
        "\n",
        "# גודל התמונה שאשתמש בו\n",
        "img_size = 120\n",
        "# מספר התמונות מתוך המאגר שאשתמש בהן\n",
        "dataset_split = 6000\n",
        "# התיקייה שממנה יילקחו התמונות\n",
        "master_dir = '/content/drive/MyDrive/Deep_Learning/PortraitData'\n",
        "# הגדרת מערכי הנתונים\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "rgb_check = []\n",
        "gray_check = []\n",
        "\n",
        "for image_file in os.listdir(master_dir)[0 : dataset_split]:\n",
        "\n",
        "  # יצירה ונרמול של התמונות הצבעוניות ובגווני אפור\n",
        "\n",
        "  rgb_image = Image.open(os.path.join(master_dir, image_file)).resize((img_size, img_size))\n",
        "  rgb_check.append(rgb_image)\n",
        "  rgb_img_array = (np.asarray(rgb_image))/255\n",
        "\n",
        "  gray_image = rgb_image.convert('L')\n",
        "  gray_check.append(gray_image)\n",
        "  gray_img_array = (np.asarray(gray_image).reshape((img_size, img_size, 1)))/255\n",
        "\n",
        "  # שמירת התמונות כמערכי מידע\n",
        "  x.append(gray_img_array)\n",
        "  y.append(rgb_img_array)\n",
        "\n",
        "# פיצול לאימון ומבחן\n",
        "#train_x, test_x, train_y, test_y = train_test_split(np.array(x), np.array(y), test_size=0.1)\n",
        "\n",
        "# שמירת המערכים כמאגרי מידע בטנזורפלו\n",
        "#dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).cache().prefetch(tf.data.experimental.AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ3HEkxZl3Tt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93p-QIDSUfgQ"
      },
      "source": [
        "## נראה שזה עובד"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAxsNB-BLBGj"
      },
      "outputs": [],
      "source": [
        "i = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOiQ0CXJUmI5"
      },
      "outputs": [],
      "source": [
        "plt.imshow(rgb_check[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8-qON_OUsO8"
      },
      "outputs": [],
      "source": [
        "plt.imshow(gray_check[i], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy1zGoskam4I"
      },
      "source": [
        "נציין שזה לא נראה נכון, אבל זה בסדר. אמנם פייפלוט משום מה מציג את התמונה בגווני ירוק במקום בגווני אפור, אבל נראה שמבחינת הרכב מערך התמונה זה בסדר"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4lOJs0sWaeU"
      },
      "outputs": [],
      "source": [
        "pix=np.array(gray_check[i])\n",
        "np.shape(pix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7bLQSotYchx"
      },
      "source": [
        "# חלק 2: מערכת הרי\"ע"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieaGl9O-Y3Ul"
      },
      "source": [
        "במערכת יש שימוש בשתי רשתות עמוקות: האחת, הנקראת המסנן, תלמד לזהות התאמה בין תמונות בגווני אפור למקבילותיהן הצבעוניות, ע\"פ מאגר הנתונים שיצרתי. השניה, הנקראת היוצר, או המחולל, תנסה לצייר את ההתאמה הצבעונית לתמונה בשחור לבן עד שהמסנן יחזיר אחוזי התאמה טובים מספיק."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6oUWa_8kOof"
      },
      "source": [
        "## ראשית, המסנן:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZeDR3e3h6e8"
      },
      "outputs": [],
      "source": [
        "def disc_model():\n",
        "  layers = [\n",
        "    tf.keras.layers.Conv2D(32, kernel_size=(7, 7), strides=1, activation='relu', kernel_regularizer='L2', input_shape=(120, 120, 3)),\n",
        "    tf.keras.layers.Conv2D(32, kernel_size=(7, 7), strides=1, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, kernel_size=(5, 5), kernel_regularizer='L2', strides=1, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=(5, 5), strides=1, activation='relu'),\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, kernel_size=(3, 3), kernel_regularizer='L2', strides=1, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(256, kernel_size=(3, 3), kernel_regularizer='L2', strides=1, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, kernel_size=(3, 3), strides=1, activation='relu'),\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    \n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "      ]\n",
        "  model = tf.keras.models.Sequential(layers, name=\"Discriminator\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9SL2u1XWP6v"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  DiscModel = disc_model()\n",
        "DiscModel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O36It4KBkVRj"
      },
      "source": [
        "## כעת, היוצר:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H6FcmXnh6bO"
      },
      "outputs": [],
      "source": [
        "def gen_model():\n",
        "  \n",
        "    inputs = tf.keras.layers.Input(shape=(img_size, img_size, 1))\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D(16, kernel_size=(5, 5), strides=1)(inputs)\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "    conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1)(conv1)\n",
        "    conv1 = tf.keras.layers.LeakyReLU()(conv1)\n",
        "    conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1)(conv1)\n",
        "    conv1 = tf.keras.layers.LeakyReLU()(conv1)\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides=1)(conv1)\n",
        "    conv2 = tf.keras.layers.LeakyReLU()(conv2)\n",
        "    conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1)(conv2)\n",
        "    conv2 = tf.keras.layers.LeakyReLU()(conv2)\n",
        "    conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1)(conv2)\n",
        "    conv2 = tf.keras.layers.LeakyReLU()(conv2)\n",
        "\n",
        "    conv3 = tf.keras.layers.Conv2D(64, kernel_size=(5, 5) ,strides=1)(conv2)\n",
        "    conv3 = tf.keras.layers.LeakyReLU()(conv3)\n",
        "    conv3 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1)(conv3)\n",
        "    conv3 = tf.keras.layers.LeakyReLU()(conv3)\n",
        "    conv3 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1)(conv3)\n",
        "    conv3 = tf.keras.layers.LeakyReLU()(conv3)\n",
        "\n",
        "    bottleneck = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1, activation='tanh', padding='same')(conv3)\n",
        "\n",
        "    concat_1 = tf.keras.layers.Concatenate()([bottleneck, conv3])\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose(128, kernel_size=(3, 3), strides=1, activation='relu')(concat_1)\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose(128, kernel_size=(3, 3), strides=1, activation='relu')(conv_up_3)\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=1, activation='relu')(conv_up_3)\n",
        "\n",
        "    concat_2 = tf.keras.layers.Concatenate()([conv_up_3, conv2])\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=1, activation='relu')(concat_2)\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=1, activation='relu')(conv_up_2)\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(5, 5), strides=1, activation='relu')(conv_up_2)\n",
        "\n",
        "    concat_3 = tf.keras.layers.Concatenate()([conv_up_2, conv1])\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=1, activation='relu')(concat_3)\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=1, activation='relu')(conv_up_1)\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose(3, kernel_size=(5, 5), strides=1, activation='relu')(conv_up_1)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs, conv_up_1, name=\"Generator\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO4FHj6m1n4U"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  GenModel = gen_model()\n",
        "GenModel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km0pmDbr4UoV"
      },
      "source": [
        "## והרי פונקציות האובדן של הרשתות:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_t-yAps0dPl"
      },
      "outputs": [],
      "source": [
        "# הגדרת פונקציות האובדן אנטרופיה מוצלבת וממוצעים ריבועיים משוקללים\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# הגדרת אובדן המסנן\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) - tf.random.uniform( shape=real_output.shape , maxval=0.1 ) , real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output) + tf.random.uniform( shape=fake_output.shape , maxval=0.1  ) , fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "# הגדרת אובדן היוצר\n",
        "def generator_loss(fake_output , real_y):\n",
        "    real_y = tf.cast( real_y , 'float32' )\n",
        "    return mse( fake_output , real_y )\n",
        "\n",
        "# נגדיר את האופטימזציות של היצרן והמסנן להיות אדם\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0005)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0005)\n",
        "\n",
        "# ניצור את פונקציות היצרן והמסנן\n",
        "generator = gen_model()\n",
        "discriminator = disc_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ0jwp0S7iWX"
      },
      "source": [
        "# חלק 3: אימון"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI_xRf7ivf_o"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 140"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwWV0mLm5ECH"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(input_x, real_y):\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    # יצירת תמונה על ידי היוצר\n",
        "    generated_images = generator(input_x , training=True)\n",
        "    # ההסתברות שהתמונה הנתונה היא האמיתית לפי המסנן\n",
        "    real_output = discriminator(real_y, training=True)\n",
        "    # ההסתברות שהתמונה שיוצרה היא האמתית לפיו\n",
        "    generated_output = discriminator(generated_images, training=True)\n",
        "    \n",
        "    # נגדיר את אובדני המסנן והיוצר\n",
        "    gen_loss = generator_loss(generated_images, real_y)\n",
        "    disc_loss = discriminator_loss(real_output, generated_output)\n",
        "\n",
        "  tf.keras.backend.print_tensor(tf.keras.backend.mean(gen_loss))\n",
        "  tf.keras.backend.print_tensor (tf.keras.backend.mean(disc_loss))\n",
        "  tf.keras.backend.print_tensor(gen_loss+disc_loss)\n",
        "\n",
        "  # חישוב הנגזרות\n",
        "  grad_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  grad_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  # אופטימיזציה עם אדם\n",
        "  generator_optimizer.apply_gradients(zip(grad_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(grad_discriminator, discriminator.trainable_variables)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3AAipdH72yS"
      },
      "outputs": [],
      "source": [
        "num_epochs = EPOCHS\n",
        "\n",
        "for i in range( num_epochs ):\n",
        "    print( i )\n",
        "    for ( x , y ) in dataset:\n",
        "        # איקס ו-וואי מייצגים אוצוות מידע\n",
        "        print( x.shape )\n",
        "        train_step( x , y )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbjFvMsEn76P"
      },
      "source": [
        "# חלק 4 – תוצאות"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PjFx6UXridt"
      },
      "outputs": [],
      "source": [
        "y = generator(test_x[0:]).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkdOLrDxYBKs"
      },
      "outputs": [],
      "source": [
        "for i in range(len(test_x)):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  or_image = plt.subplot(3,3,1)\n",
        "  or_image.set_title('Grayscale Input', fontsize=16)\n",
        "  plt.imshow( test_x[i].reshape((120,120)) , cmap='gray' )\n",
        "\n",
        "  in_image = plt.subplot(3,3,2)    \n",
        "  image = Image.fromarray( ( y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "  image = np.asarray( image )\n",
        "  in_image.set_title('Colorized Output', fontsize=16)\n",
        "  plt.imshow( image )\n",
        "\n",
        "  ou_image = plt.subplot(3,3,3)\n",
        "  image = Image.fromarray( ( test_y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "  ou_image.set_title('Ground Truth', fontsize=16)\n",
        "  plt.imshow( image )\n",
        "\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "uHPXpCUrKtl2",
        "93p-QIDSUfgQ",
        "km0pmDbr4UoV",
        "BbjFvMsEn76P"
      ],
      "name": "YotamKatzir_Image_Colourization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZzT66VwCDuVt9Ug0e4F51",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}